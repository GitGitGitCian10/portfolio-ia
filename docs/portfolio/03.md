---
title: "Entrada 03 â€” RegresiÃ³n LogÃ­stica y Lineal"
date: 2025-10-10
---

# Entrada 03 â€” RegresiÃ³n LogÃ­stica y Lineal

## Contexto
En este artÃ­culo utilizaremos tÃ©cnicas de regresiÃ³n lineal y logÃ­stica
sobre 2 diferentes dataset y finalmente realizaremos una comparaciÃ³n
de las cualidades de ambas tÃ©cnicas y sus casos de uso.

Para la regresiÃ³n lineal utilizaremos el dataset de Boston Housing, buscando
determinar el valor mediano de las propiedades, y para la regresiÃ³n logÃ­stica
utilizaremos el dataset de Breast Cancer Wisconsin, buscando determinar si
un tumor es benigno o maligno.

## Objetivos
- Crear una implementaciÃ³n bÃ¡sica de regresiÃ³n lineal
- Crear una implementaciÃ³n bÃ¡sica de regresiÃ³n logÃ­stica
- Entender las diferencias de ambas tÃ©cnicas y casos de uso

## Actividades (con tiempos estimados)
- InvestigaciÃ³n de LinearRegression y LogisticRegression de Scikit-learn â€” 5 min
- InvestigaciÃ³n de mÃ©tricas a utilizar â€” 5 min
- InvestigaciÃ³n del Dataset de Boston Housing â€” 10 min
- Desarrollo del modelo de regresiÃ³n lineal â€” 15 min
- InvestigaciÃ³n del Dataset de Breast Cancer Wisconsin â€” 10 min
- Desarrollo del model de regresiÃ³n logÃ­stica â€” 15 min
- ComparaciÃ³n de los modelos â€” 8 min

## Desarrollo
### 1. InvestigaciÃ³n de LinerRegression y LogisticRegression

#### LinearRegression:

- La regresiÃ³n linear predice valores continuos, sirve para resolver
problemas de predicciÃ³n numÃ©rica o estimaciÃ³n, como estimar el precio
de una casa en base a sus caracterÃ­sticas.
- ParÃ¡metros importantes:
    - fit_intercept: determina si el modelo calcula el bias. 
    - positive: determina si los coeficientes debe ser exclusivamente positivos.

#### LogisticRegression:

Por la investigaciÃ³n de LogisticRegression (y train_test_split), refiÃ©rase a [De datos crudos a predicciones: CÃ³mo potenciar el modelo base con Feature Engineering](02.md).

### 2. InvestigaciÃ³n de mÃ©tricas a utilizar

MÃ©tricas para regresiÃ³n lineal:

- MAE (Mean Absolute Error): Promedio de los errores absolutos sin importar si son positivos o negativos.
- MSE (Mean Squared Error):	Promedio de los errores cuadrÃ¡ticos (elevados al cuadrado), penaliza mÃ¡s los errores grandes.
- RMSE: RaÃ­z cuadrada del MSE, vuelve a las unidades originales del problema.
- R<sup>2</sup>: Indica quÃ© porcentaje de la variabilidad es explicada por el modelo (0-1, donde 1 es perfecto).
- MAPE: Error porcentual promedio, Ãºtil para comparar modelos con diferentes escalas o unidades.

MÃ©tricas para regresiÃ³n logÃ­stica:

- Accuracy: Porcentaje de predicciones correctas sobre el total.
- Precision: De todas las predicciones positivas (de la clase de interÃ©s), Â¿cuÃ¡ntas fueron realmente correctas?
- Recall (Sensibilidad): De todos los casos positivos reales, Â¿cuÃ¡ntos detectamos?
- F1-Score: Promedio armÃ³nico entre precision y recall.
- Matriz de ConfusiÃ³n: Tabla que muestra predicciones vs valores reales.

### 3. InvestigaciÃ³n del Dataset de Boston Housing
El dataset consiste en datos acerca de alojamientos en el Ã¡rea de Boston, Massachusetts;
teniendo datos referentes a la poblaciÃ³n, referentes a la superficie en base a quÃ© la ocupa 
y referentes a los alojamientos mismos, estando dentro de estos datos los valores medianos
de los hogares ocupados.

Cada fila del dataset consiste en un vecindario dentro del Ã¡rea de Boston y, en este caso,
la variable objetivo a predecir serÃ¡ MEDV o el valor mediano de hogares ocupados.

#### Columnas:

- CRIM: Crimen  per cÃ¡pita por pueblo
- ZN: ProporciÃ³n de terreno residencial zonificado para lotes por encima de 25000 pies cuadrados
- INDUS: ProporciÃ³n de acres de negocios no minoristas por pueblo
- CHAS: Booleano que determina si el vecindario limita con el rÃ­o Charles (1 sÃ­, 0 no)
- NOX: ConcentraciÃ³n de Ã³xido nÃ­trico (partes por 10 millones)
- RM: NÃºmero promedio de habitaciones por vivienda
- AGE: ProporciÃ³n de unidades ocupadas construidas previo al 1940
- DIS: Distancias ponderadas a 5 centros de empleo en Boston
- RAD: Ãndice de accesibilidad a autopistas radiales
- TAX: Tasa de impuesto a valor total de la propiedad por cada 10000 dolares
- PTRATIO - RelaciÃ³n estudiante-profesor por pueblo.
- B: 1000(Bk - 0.63)^2 donde Bk es la proporciÃ³n de personas negras por pueblo
- LSTAT: Porcentaje de poblaciÃ³n de bajo estado econÃ³mico
- MEDV: Valor mediano de hogares ocupados expresados en 1000 de dolares

### 4. Desarrollo del modelo de regresiÃ³n lineal

Primeramente, cargaremos el dataset y analizaremos brevemente su contenido y forma,
y luego prepararemos la variable con las features (X) y la variable objetivo (y).

```python linenums="1"
# === CARGAR DATOS DE CASAS EN BOSTON ===

# 1. Cargar el dataset desde una URL
url = "https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv"
boston_data = pd.read_csv(url)

print("ğŸ  DATASET: Boston Housing")
print(f"   ğŸ“Š Forma: {boston_data.shape}")
print(f"   ğŸ“‹ Columnas: {list(boston_data.columns)}")

# 2. Explorar los datos bÃ¡sicamente
print("\nğŸ” Primeras 5 filas:")
print(boston_data.head())

# 3. Preparar X (variables independientes) e y (variable dependiente)
# La columna 'medv' es el precio de la casa que queremos predecir
X = boston_data.drop('medv', axis=1)  # Todas las columnas EXCEPTO la que queremos predecir
y = boston_data['medv']                # Solo la columna que queremos predecir

print(f"\nğŸ“Š X tiene forma: {X.shape}")
print(f"ğŸ“Š y tiene forma: {y.shape}")
print(f"ğŸ¯ Queremos predecir: Precio de casas en miles de USD")
print(f"ğŸ“ˆ Precio mÃ­nimo: ${y.min():.1f}k, Precio mÃ¡ximo: ${y.max():.1f}k")
```

![](../assets/03-01.png)


Luego, utilizando train_test_split dividimos el set en 80% para entrenamiento y el 20% restante
para validaciÃ³n.

```python linenums="1"
# 1. Dividir datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"ğŸ“Š Datos de entrenamiento: {X_train.shape[0]} casas")
print(f"ğŸ“Š Datos de prueba: {X_test.shape[0]} casas")
```

![](../assets/03-02.png)

Creamos y entrenamos el modelo.

```python linenums="1"
# 2. Crear y entrenar el modelo
modelo_regresion = LinearRegression()
modelo_regresion.fit(X_train, y_train)

print("âœ… Modelo entrenado!")
```

Predecimos en base al set de entrenamiento, evaluamos en base a distintas mÃ©tricas
y comparamos los resultados reales con las predicciones del modelo.

```python linenums="1"
# 3. Hacer predicciones
predicciones = modelo_regresion.predict(X_test)

print(f"\nğŸ”® Predicciones hechas para {len(predicciones)} casas")

# 4. Evaluar quÃ© tan bueno es el modelo con MÃšLTIPLES MÃ‰TRICAS
mae = mean_absolute_error(y_test, predicciones)
mse = mean_squared_error(y_test, predicciones)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, predicciones)

# Calcular MAPE manualmente
mape = np.mean(np.abs((y_test - predicciones) / y_test)) * 100

print(f"\nğŸ“ˆ MÃ‰TRICAS DE EVALUACIÃ“N:")
print(f"   ğŸ“Š MAE (Error Absoluto Medio): ${mae:.2f}k")
print(f"   ğŸ“Š MSE (Error CuadrÃ¡tico Medio): {mse:.2f}")
print(f"   ğŸ“Š RMSE (RaÃ­z del Error CuadrÃ¡tico): ${rmse:.2f}k")
print(f"   ğŸ“Š RÂ² (Coeficiente de determinaciÃ³n): {r2:.3f}")
print(f"   ğŸ“Š MAPE (Error Porcentual Absoluto): {mape:.1f}%")

print(f"\nğŸ” INTERPRETACIÃ“N:")
print(f"   ğŸ’° En promedio nos equivocamos por ${mae:.2f}k (MAE)")
print(f"   ğŸ“ˆ El modelo explica {r2*100:.1f}% de la variabilidad (RÂ²)")
print(f"   ğŸ“Š Error porcentual promedio: {mape:.1f}% (MAPE)")

# 5. Comparar algunas predicciones reales vs predichas
print(f"\nğŸ” EJEMPLOS (Real vs Predicho):")
for i in range(5):
    real = y_test.iloc[i]
    predicho = predicciones[i]
    print(f"   Casa {i+1}: Real ${real:.1f}k vs Predicho ${predicho:.1f}k")

print(f"\nValor promedio de las casas: ${y.mean()}k")
print(f"Valor mediano de las casas: ${y.median()}")
```

![](../assets/03-03.png)

Viendo estos resultados, con un error absoluto medio (MAE) de $3.19k pero siendo el valor
promedio de las casas $22.53k, esto constituye un error porcentual absoluto (MAPE) del 16.9%;
por lo tanto, si bien este modelo de regresiÃ³n lineal resultÃ³ fÃ¡cil y simple de implementar,
si se estÃ¡ buscando una estimaciÃ³n con un mÃ¡rgen de error mÃ¡s estricto se deberÃ¡ optar por
otro tipo de modelo, realizar feature engineering en las features o aumentar el conjuntos de datos.
Por otro lado, el modelo consigue un coeficiente de determinaciÃ³n de 0.669, lo que podrÃ­a llegar
a ser aceptable considerando que predice casi un 67% de la variaciÃ³n de los precios de las
propiedades a travÃ©s de los datos de entrada.

### 5. InvestigaciÃ³n del Dataset de Breast Cancer Wisconsin
El dataset consiste en datos de pacientes que fueron estudiados y determinados (o no) tener
cÃ¡ncer de mama, teniendo un resumen de las caracterÃ­sticas de los nÃºcleos celulares en la
imÃ¡gen digitalizada de la masa de los senos de cada paciente.

Cada fila del dataset contiene distintas mÃ©tricas de las distintas caracterÃ­sticas de los
nÃºcleos celulares observados en las imagenes tomadas de cada paciente, ademÃ¡s de 2 valores
adicionales como el id y la variable objetivo que determina si el tumor es maligno o no.

#### Columnas:

- ID number: nÃºmero identificador
- Diagnosis: M = maligno, B = benigno
- radio: promedio de distancia del centro al perimetro
- textura: desviaciÃ³n estÃ¡ndar de valores de escala de grises (determina la
uniformidad y rugosidad de la superficie del nÃºcleo)
- perimetro: valor del perimetro
- Ã¡rea: valor del Ã¡rea
- suavidad: variaciÃ³n local de los radios
- compactibilidad: perimetro^2 / area - 1.0
- concavidad: severidad de las porciones cÃ³ncavas del contorno
- puntos cÃ³ncavos: nÃºmero de porciones cÃ³ncavas del contorno
- simetrÃ­a: medida de simetrÃ­a del nÃºcleo
- dimension fractal: aproximaciÃ³n de la lÃ­nea costal - 1

!!! note "Nota"
    Si bien menciono estas caracterÃ­sticas como columnas, a partir del radio hasta la dimensiÃ³n fractal,
    se toma el promedio, error estÃ¡ndar y el peor (promedio de los tres valores mÃ¡s grandes); y estas 3 medidas forman
    cada columna a partir de la 3 hasta la 32. Por ejemplo, la columna 3 es el promedio del radio, la columna
    13 es el error estÃ¡ndar del radio y la columna 23 es el peor de los radios; de manera similar ocurre con las
    otras caracterÃ­sticas.


### 6. Desarrollo del model de regresiÃ³n logÃ­stica

Primeramente, cargaremos el dataset y analizaremos brevemente su contenido y forma,
y luego prepararemos la variable con las features (X) y la variable objetivo (y).

```python linenums="1"
# === CARGAR DATOS DE DIAGNÃ“STICO DE CÃNCER ===

# 1. Cargar el dataset de cÃ¡ncer de mama (que viene con sklearn)
cancer_data = load_breast_cancer()

# 2. Convertir a DataFrame para verlo mejor
X_cancer = pd.DataFrame(cancer_data.data, columns=cancer_data.feature_names)
y_cancer = cancer_data.target  # 0 = maligno, 1 = benigno

print("ğŸ¥ DATASET: Breast Cancer (DiagnÃ³stico)")
print(f"   ğŸ“Š Pacientes: {X_cancer.shape[0]}")
print(f"   ğŸ“Š CaracterÃ­sticas: {X_cancer.shape[1]}")
print(f"   ğŸ¯ Objetivo: Predecir si tumor es benigno (1) o maligno (0)")

# 3. Ver balance de clases
casos_malignos = (y_cancer == 0).sum()
casos_benignos = (y_cancer == 1).sum()

print(f"\nğŸ“Š DISTRIBUCIÃ“N:")
print(f"   âŒ Casos malignos: {casos_malignos}")
print(f"   âœ… Casos benignos: {casos_benignos}")
```

![](../assets/03-04.png)

Luego, utilizando train_test_split dividimos el set en 80% para entrenamiento y el 20% restante
para validaciÃ³n.

```python linenums="1"
# 1. Dividir datos en entrenamiento y prueba
X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test_split(
    X_cancer, y_cancer, test_size=0.2, random_state=42
)

print(f"ğŸ“Š Datos de entrenamiento: {X_train_cancer.shape[0]} pacientes")
print(f"ğŸ“Š Datos de prueba: {X_test_cancer.shape[0]} pacientes")
```

![](../assets/03-05.png)

Creamos y entrenamos el modelo.

```python linenums="1"
# 2. Crear y entrenar modelo de regresiÃ³n logÃ­stica
modelo_clasificacion = LogisticRegression(max_iter=5000, random_state=42)
modelo_clasificacion.fit(X_train_cancer, y_train_cancer)

print("âœ… Modelo de clasificaciÃ³n entrenado!")
```

Predecimos en base al set de entrenamiento, evaluamos en base a distintas mÃ©tricas
y comparamos los resultados reales con las predicciones del modelo.

```python linenums="1"
# 3. Hacer predicciones
predicciones_cancer = modelo_clasificacion.predict(X_test_cancer)

# 4. Evaluar con MÃšLTIPLES MÃ‰TRICAS de clasificaciÃ³n
exactitud = accuracy_score(y_test_cancer, predicciones_cancer)
precision = precision_score(y_test_cancer, predicciones_cancer)
recall = recall_score(y_test_cancer, predicciones_cancer)
f1 = f1_score(y_test_cancer, predicciones_cancer)

print(f"\nğŸ“ˆ MÃ‰TRICAS DE CLASIFICACIÃ“N:")
print(f"   ğŸ¯ Exactitud (Accuracy): {exactitud:.3f} ({exactitud*100:.1f}%)")
print(f"   ğŸ¯ PrecisiÃ³n (Precision): {precision:.3f} ({precision*100:.1f}%)")
print(f"   ğŸ¯ Recall (Sensibilidad): {recall:.3f} ({recall*100:.1f}%)")
print(f"   ğŸ¯ F1-Score: {f1:.3f}")

# Mostrar matriz de confusiÃ³n de forma simple
matriz_confusion = confusion_matrix(y_test_cancer, predicciones_cancer)
print(f"\nğŸ”¢ MATRIZ DE CONFUSIÃ“N:")
print(f"   ğŸ“Š {matriz_confusion}")
print(f"   ğŸ“‹ [Verdaderos Negativos, Falsos Positivos]")
print(f"   ğŸ“‹ [Falsos Negativos, Verdaderos Positivos]")

# Reporte detallado
print(f"\nğŸ“‹ REPORTE DETALLADO:")
print(classification_report(y_test_cancer, predicciones_cancer, target_names=['Maligno', 'Benigno']))

print(f"\nğŸ” INTERPRETACIÃ“N MÃ‰DICA:")
print(f"   ğŸ©º Precision: De los casos que predecimos como benignos, {precision*100:.1f}% lo son realmente")
print(f"   ğŸ©º Recall: De todos los casos benignos reales, detectamos {recall*100:.1f}%")
print(f"   ğŸ©º F1-Score: Balance general entre precision y recall: {f1:.3f}")

# 5. Ver ejemplos especÃ­ficos
print(f"\nğŸ” EJEMPLOS (Real vs Predicho):")
for i in range(5):
    real = "Benigno" if y_test_cancer[i] == 1 else "Maligno"
    predicho = "Benigno" if predicciones_cancer[i] == 1 else "Maligno"
    print(f"   Paciente {i+1}: Real: {real} vs Predicho: {predicho}")
```

![](../assets/03-06.png)

En este caso, los resultados obtenidos son bastante decentes, siendo el mÃ¡s bajo de estos (precisiÃ³n) tan sÃ³lo
ligeramente inferior al 95% y teniendo un F1-Score del 96.6%. 

Si bien no me es posible determinar la causa de su mejor resultado en comparaciÃ³n al obtenido por la regresiÃ³n
lineal, puede que la mayor cantidad de features, un mayor relacionamiento entre estas y la variable objetivo, o
simplemente sea mÃ¡s sencillo para un modelo predecir o 0 o 1 que en un rango entre dos nÃºmeros sean las causantes
de este resultado superior.


### 7. ComparaciÃ³n de los modelos

| Aspecto           | RegresiÃ³n Lineal | RegresiÃ³n LogÃ­stica               |
|---------------------|:------:|----------------------------------|
| QuÃ© predice |  Valores continuos  |   Pertenencia a una clase   |
| Ejemplo de uso      |  EstimaciÃ³n numÃ©rica, cÃ¡lculos de precios o cantidades   | ClasificaciÃ³n binaria, detecciÃ³n de spam, determinar supervivencia de pasajeros    |
| Rango de salida     | Todos los nÃºmeros reales   | 0 o 1   |
| MÃ©trica principal   | MAE o RMSE | F1-Score

!!! note "Nota"
    La mÃ©trica principal de la regresiÃ³n lineal podrÃ­a ser MAE o RMSE dependiendo de la
    importancia de errores grandes al contexto. Adicionalmente, podrÃ­a tambiÃ©n tomarse
    R<sup>2<sup> si interesa quÃ© tan bien el modelo captura la variabilidad de los datos.

### Preguntas Posteriores

- Â¿CuÃ¡l es la diferencia principal entre regresiÃ³n lineal y logÃ­stica?

Una regresiÃ³n lineal predice ultimamente valores continuos y se utiliza para estimaciones
de precios, cÃ¡lculos de ventas, anÃ¡lisis del clima o cantidades, etc.; mientras que la
regresiÃ³n logÃ­stica predice la pertenencia de ciertos datos a una clase y se utiliza para
predecir si un paciente tiene cierta enfermedad, determinar si una imagen es de un gato o
no, analizar si un cliente es leal o no, etc.

- Â¿Por quÃ© dividimos los datos en entrenamiento y prueba?

Para verificar el correcto funcionamiento de un modelo, necesitamos, por lo menos, un conjunto de
datos de enternamiento y otro de validaciÃ³n; como ocasionalmente se suele poseer un conjunto Ãºnico
de datos, este se divide en parte para el entrenamiento y otra parte para la validaciÃ³n.

- Â¿QuÃ© significa una exactitud del 95%?

Una exactitud del 95% indica que el modelo asigna correctamente las clases a un 95% de
las predicciones, es decir: (TN + TP)/(TN + TP + FN + FP) = 0.95.

- Â¿CuÃ¡l es mÃ¡s peligroso: predecir "benigno" cuando es "maligno", o al revÃ©s?

Considero que es mÃ¡s peligroso predecir "benigno" cuando es "maligno", ya que, en caso contrario,
muy probablemente se realizacen estudios adicionales que finalmente determinen que el paciente
estaba sano y concluirÃ­a con una mera pÃ©rdida monetaria. Sin embargo, en el primer caso, al
determinar que el paciente estaba "sano", puede que no se realicen anÃ¡lisis posteriores y que
sÃ³lo se enteren de la verdad cuando sea demasiado tarde, concluyendo en un desastre tanto para
el paciente, su personas cercanas y, ultimamente, la entidad que dio el veredicto del paciente
que podrÃ­a ser involucrada en problemas legales.

- Â¿CuÃ¡l modelo usarÃ­as para predecir el salario de un empleado?

UtilizarÃ­a una regresiÃ³n lineal con variable objetivo el salario del empleado.

- Â¿CuÃ¡l modelo usarÃ­as para predecir si un email es spam?

UtilizarÃ­a una regresiÃ³n logÃ­stica con clases spam (1) y no spam (0).

- Â¿Por quÃ© es importante separar datos de entrenamiento y prueba?

Es importante separar datos de entrenamiento y prueba ya que, en el entrenamiento,
el modelo puede llegar a "memorizar" completamente el conjuntos de datos y no aprender 
los patrones generales que explican la realidad con otros datos.


## Evidencias
- [Link al colab](https://colab.research.google.com/drive/1dQVgfHaU2pkt2yJlHMqDmNGCkin0YCTB?usp=sharing)

## ReflexiÃ³n
Considero que la regresiÃ³n lineal puede ser una herramienta muy Ãºtil a futuro y me parece 
interesante para indagar en maneras de mejorar sus resultados.

La regresiÃ³n logÃ­stica parece funcionar bastante bien con el conjunto de datos utilizado,
se podrÃ­a experimentar con otros datasets para corroborar el correcto funcionamiento de
este modelo.

Finalmente, puedo ver la necesidad de tantos tipos diferentes de mÃ©tricas, desde algunas mÃ¡s generales
hasta otras mÃ¡s especÃ­icas, teniendo cada una su uso que hace que no sea completamente reemplazable por 
otra y que en conjunto le dan mayor profundidad al anÃ¡lisis; familiarizarme con estas mÃ©tricas serÃ¡
muy importante para las siguientes prÃ¡cticas.

## Referencias

- [Mastering Logistic Regression with Scikit-Learn: A Complete Guide](https://www.digitalocean.com/community/tutorials/logistic-regression-with-scikit-learn)